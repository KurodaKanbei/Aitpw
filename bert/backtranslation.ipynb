{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"FM97P8ZC104s"},"outputs":[],"source":["!nvidia-smi\n","\n","!pip install transformers\n","!pip install --no-cache-dir transformers sentencepiece\n","!pip install datasets\n","!pip install sacremoses\n","import sys, os, random\n","from tqdm import tqdm\n","from transformers.pipelines.text2text_generation import TranslationPipeline as trans_pipeline\n","import torch\n","from transformers.pipelines import pipeline\n","from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n","\n","from google.colab import drive\n","drive.mount('/content/drive')\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"HTFNhRbm3e6H"},"outputs":[],"source":["target_lang = 'de' # 'de', 'hi'\n","print(target_lang)\n","trans_model_name = 'Helsinki-NLP/opus-mt-en-' + target_lang\n","backtrans_model_name = 'Helsinki-NLP/opus-mt-' + target_lang + '-en'\n","\n","#device = xm.xla_device()\n","device = torch.device('cuda:0')\n","\n","data_dir=\"drive/MyDrive/data/\"\n","pos_file_name = \"train_neg_full_preprocessed.txt\"\n","pos_dest_file_name = \"train_neg_full_translated.txt\"\n","\n","trans_tokenizer = AutoTokenizer.from_pretrained(trans_model_name)\n","trans_model = AutoModelForSeq2SeqLM.from_pretrained(trans_model_name)\n","translator = pipeline(task='translation', model=trans_model, tokenizer=trans_tokenizer, batch_size=32, device=device)\n","\n","backtrans_tokenizer = AutoTokenizer.from_pretrained(backtrans_model_name)\n","backtrans_model = AutoModelForSeq2SeqLM.from_pretrained(backtrans_model_name)\n","backtranslator = pipeline(task='translation', model=backtrans_model, tokenizer=backtrans_tokenizer, batch_size=32, device=device)\n","\n","trans_model.eval()\n","backtrans_model.eval()\n","\n","s = \"\"\n","\n","pos_file = open(data_dir+pos_file_name, encoding=\"utf8\").read().split(\"\\n\")\n","for i in tqdm(range(0, len(pos_file), 32)):\n","  \n","  if random.random() < 0.5:\n","    continue\n","\n","  ls = pos_file[i:i+32]\n","  for j in range(len(ls)):\n","    if len(ls[j])<513:\n","      pass\n","    else:\n","      t = ls[j][:512].split(\" \")\n","      s_ = \"\"\n","      for k in range(len(t)-1):\n","        s_ += t[k]+\" \"\n","      ls[j] = s_[:-1]\n","  \n","  output = translator(ls, max_length=512)\n","  output = [obj['translation_text'] for obj in output]\n","\n","  for j in range(len(output)):\n","    if len(output[j])<513:\n","      pass\n","    else:\n","     t = output[j][:512].split(\" \")\n","     s_ = \"\"\n","     for k in range(len(t)-1):\n","       s_ += t[k]+\" \"\n","     output[j] = s_[:-1]\n","  \n","  output = backtranslator(output, max_length=512)\n","  for out in output:\n","    s+=out[\"translation_text\"]+\"\\n\"\n","\n","\n","with open(data_dir+pos_dest_file_name, 'w', encoding='UTF-8') as f:\n","        f.writelines(s)\n","\n"]}],"metadata":{"accelerator":"GPU","colab":{"background_execution":"on","collapsed_sections":[],"machine_shape":"hm","name":"backtranslation.ipynb","private_outputs":true,"provenance":[],"authorship_tag":"ABX9TyPsrxsugQnIjeO6f6ND65xC"},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}